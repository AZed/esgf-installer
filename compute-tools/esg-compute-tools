#!/bin/bash

#####
# esg-compute-tools: ESGF Node Application Stack - Compute Tools
# description: Compute tools installer for the ESGF Node application stack
#
#****************************************************************************
#*                                                                          *
#*    Organization: Lawrence Livermore National Lab (LLNL)                  *
#*    Directorate: Computation                                              *
#*    Department: Computing Applications and Research                       *
#*    Division: S&T Global Security                                         *
#*    Matrix: Atmospheric, Earth and Energy Division                        *
#*    Program: PCMDI                                                        *
#*    Project: Earth Systems Grid Fed (ESGF) Node Software Stack            *
#*    First Author: Eugenia Gabrielova (gabrielov1@llnl.gov)                *
#*                                                                          *
#****************************************************************************
#*                                                                          *
#*   Copyright (c) 2009, Lawrence Livermore National Security, LLC.         *
#*   Produced at the Lawrence Livermore National Laboratory                 *
#*   Written by: Gavin M. Bell (gavin@llnl.gov),                            * 
#*               Eugenia Gabrielova (gabrielov1@llnl.gov)                   *
#*   LLNL-CODE-420962                                                       *
#*                                                                          *
#*   All rights reserved. This file is part of the:                         *
#*   Earth System Grid Fed (ESGF) Node Software Stack, Version 1.0          *
#*                                                                          *
#*   For details, see http://esgf.org/                                      *
#*   Please also read this link                                             *
#*    http://esgf.org/LICENSE                                               *
#*                                                                          *
#*   * Redistribution and use in source and binary forms, with or           *
#*   without modification, are permitted provided that the following        *
#*   conditions are met:                                                    *
#*                                                                          *
#*   * Redistributions of source code must retain the above copyright       *
#*   notice, this list of conditions and the disclaimer below.              *
#*                                                                          *
#*   * Redistributions in binary form must reproduce the above copyright    *
#*   notice, this list of conditions and the disclaimer (as noted below)    *
#*   in the documentation and/or other materials provided with the          *
#*   distribution.                                                          *
#*                                                                          *
#*   Neither the name of the LLNS/LLNL nor the names of its contributors    *
#*   may be used to endorse or promote products derived from this           *
#*   software without specific prior written permission.                    *
#*                                                                          *
#*   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS    *
#*   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT      *
#*   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS      *
#*   FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL LAWRENCE    *
#*   LIVERMORE NATIONAL SECURITY, LLC, THE U.S. DEPARTMENT OF ENERGY OR     *
#*   CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,           *
#*   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT       *
#*   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF       *
#*   USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND    *
#*   ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,     *
#*   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT     *
#*   OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF     *
#*   SUCH DAMAGE.                                                           *
#*                                                                          *
#****************************************************************************
#####

#####
# Description: Installer for ESG Compute Tools
# Implemented Tools: Spark, Hadoop, Zookeeper
# Tools in Progress: Yarn (Hadoop Streaming), Mesos (Cluster Management), Cascalog
# Authors: Eugenia Gabrielova {gabrielov1@llnl.gov, genia.likes.science@gmail.com}
####

#####
# uses: git, tar
#####

#--------------
# User Defined / Settable (public)
#--------------
install_prefix=${install_prefix:-"/usr/local"}
DEBUG=${DEBUG:-0}
git_placeholder="$install_prefix/git"
git_exec_path_param="--exec-path=$git_placeholder/libexec/git-core"
java_placeholder="$install_prefix/java"
java_install_path_config_param="--with-java-home=$java_placeholder/bin/java"
compress_extensions=".tar.gz|.tar.bz2|.tgz|.bz2|.tar"
envfile="/etc/esg.env"
esg_functions_file=./esgf-functions
esg_compute_languages_file=./esg-compute-languages

#--------------------------------
# External programs' versions
#--------------------------------
zookeeper_version=${zookeeper_version:="3.3.5"} #
zookeeper_min_version=${zookeeper_min_version:="3.3.3"}
zookeeper_max_version=${zookeeper_max_version:="3.4.3"}
mesos_version=${mesos_version:="0.9.0"}
mesos_min_version=${mesos_min_version:="0.9.0"}
spark_version=${spark_version:="0.5.0"}
spark_min_version=${spark_min_version:="0.5.0"}
hadoop_version=${hadoop_version:="1.0.3"}
hadoop_min_version=${hadoop_min_version:="1.0.1"}
hadoop_max_version=${hadoop_max_version:="1.0.4"}

#--------------------------------
# External programs' script variables
#--------------------------------
mesos_install_dir=${MESOS_HOME:-${install_prefix}/mesos}
mesos_git_url="git://git.apache.org/mesos.git"
spark_install_dir=${SPARK_HOME:-${install_prefix}/spark}
spark_git_url="git://github.com/mesos/spark.git"
zookeeper_install_dir=${ZOOKEEPER_HOME:-${install_prefix}/zookeeper}
zookeeper_dist_url=http://www.gtlib.gatech.edu/pub/apache/zookeeper/zookeeper-${zookeeper_version}/zookeeper-${zookeeper_version}.tar.gz
hadoop_install_dir=${HADOOP_HOME:-${install_prefix}/hadoop}
hadoop_dist_url=http://www.gtlib.gatech.edu/pub/apache/hadoop/common/hadoop-${hadoop_version}/hadoop-${hadoop_version}.tar.gz

[ -e "${envfile}" ] && source ${envfile} && ((VERBOSE)) && printf "sourcing environment from: ${envfile} \n"
[ -e ${esg_functions_file} ] && source ${esg_functions_file} && ((VERBOSE)) && printf "sourcing from: ${esg_functions_file} \n"

# This is sourcing for now to help Scala/Clojure dependent frameworks install. Once the environment stuff in those is correctly 
# implemented, it will not be necessary to source this file.
[ -e ${esg_compute_languages_file} ] && source ${esg_compute_languages_file} && ((VERBOSE)) && printf "sourcing from: ${esg_compute_languages_file} \n"

#####
# Mesos (Cluster manager for resource sharing across distirbuted applications)
#####
setup_mesos() {
	# Checking Mesos Version
	echo
	echo -n "Checking for mesos >= ${mesos_min_version}"
	if [ -e ${mesos_install_dir} ]; then
		
		# Unconfigured Mesos will not be able to check its version
		if [ ! -e ${mesos_install_dir}/configure ]; then
			(cd ${mesos_install_dir} && ./bootstrap)
		fi
		# TODO Maybe rebuild Mesos method would be useful

		local mesos_current_version=`${mesos_install_dir}/configure -version | head -1 | awk '{print $3}'`
		check_version_helper $mesos_current_version ${mesos_min_version} 
		[ $? == 0 ] && (( ! force_install )) && echo " [OK]" && return 0
	else
		echo
		echo "No Mesos installation detected"
	fi

	echo
	echo "**********************************"
	echo "Setting Up Mesos ${mesos_version}"
	echo "**********************************"
	echo 

	# Retrieve Mesos Source and build after configuration for ESGF tools
	# Uses: Hadoop, Zookeeper, Java, Python
	git ${git_exec_path_param} clone ${mesos_git_url} ${mesos_install_dir}
	(cd ${mesos_install_dir} && ./bootstrap && ./configure && make && make install)

	# TODO make check hangs on zookeeper install
	# TODO Check download errors (git failure)
	# Boilerplate: [ $? != 0 ] && echo " ERROR: Could not clone Mesos: ${mesos_git_url}" && popd && checked_done 1
	# TODO Mesos /usr/local configuration
	# TODO ./configure with Hadoop, Zookeeper, Java, Python from /usr/local
    
	# Add Mesos home to environment and TODO install manifest
	write_env_mesos
}

reinstall_mesos () {
	echo
}

write_env_mesos() {
	echo "export MESOS_HOME=${mesos_install_dir}" >> ${envfile}
	dedup ${envfile} && source ${envfile}
	return 0
}

config_mesos() {
    echo
}

test_mesos() {
    echo
    echo "---------------"
    echo "Mesos Test Placeholder"
    echo "---------------"
    echo
}

run_mesos() {
	echo
}

clean_mesos() {
	doit="N"
    if [ -e ${mesos_install_dir} ]; then
        read -e -p "remove cluster management framework Mesos? (${mesos_install_dir}) [y/N]: " doit
        if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
        	echo "removing ${mesos_install_dir}"
        	rm -rf ${mesos_install_dir}
        	[ $? != 0 ] && echo "ERROR: Unable to remove ${mesos_install_dir}"
            remove_env MESOS_HOME
            #remove_install_log_entry mesos
        fi  
    fi  
}

#####
# Spark (Mapreduce framework in Scala, targeted at iterative applications that make use of working
# sets of data)
#####

setup_spark() {
	# Checking for Spark Version
	echo
	echo -n "Checking for spark >= ${spark_min_version}"
	if [ -e ${spark_install_dir} ]; then
		local spark_current_version=$(cd ${spark_install_dir} && sbt/sbt version | awk 'NR==5{split($3,array,"-")} END{print array[1]}' )
		check_version_helper $spark_current_version ${spark_min_version}
		[ $? == 0 ] && (( ! force_install )) && echo " [OK]" && return 
	else
		echo
		echo "No Spark installation detected"
	fi

    echo
	echo "*****************************"
	echo "Setting Up Spark ${spark_version}"
	echo "*****************************"
	echo

	# Retrieve and build Spark
	git ${git_exec_path_param} clone ${spark_git_url} ${spark_install_dir}
	config_build_spark
	(cd ${spark_install_dir} && sbt/sbt compile)
	
	# TODO check for download errors or git failures
	# TODO write spark test code 
	
	# Add Spark home to environment and TODO install manifest
	write_env_spark
}

config_build_spark() {
	# It is more reliable to export relevant environment variables to
	# Spark's configuration files; this might be a byproduct of the standalone
	# compute tools installation.

	# Spark/Scala Configuration
	echo "SCALA_HOME=/usr/local/scala" >> ${spark_install_dir}/conf/spark-env.sh
	dedup ${spark_install_dir}/conf/spark-env.sh && source ${spark_install_dir}/conf/spark-env.sh

	# Java configuration
}

write_env_spark() {
	echo "export SPARK_HOME=${spark_install_dir}" >> ${envfile}	
	dedup ${envfile} && source ${envfile}
	return 0
}

config_spark() {
	echo
}

test_spark() {
	echo
}

run_spark() {
	echo
}

clean_spark() {
	doit="N"
    if [ -e ${spark_install_dir} ]; then
        read -e -p "remove iterative computation framework Spark? (${spark_install_dir}) [y/N]: " doit
        if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
        	echo "removing ${spark_install_dir}"
        	rm -rf ${spark_install_dir}
        	[ $? != 0 ] && echo "ERROR: Unable to remove ${spark_install_dir}"
            remove_env SPARK_HOME
            #remove_install_log_entry spark
        fi  
    fi  
}

#####
# Hadoop (MapReduce distributed computing on HDFS)
#####
setup_hadoop() {
	# Check Hadoop Version
	echo
	echo -n "Checking for Hadoop >= ${hadoop_min_version}"
	if [ -e ${hadoop_install_dir} ]; then
        local hadoop_current_version=$(${hadoop_install_dir}/bin/hadoop version | head -1 | awk '{print $2}')
		local hadoop_version_number=${hadoop_current_version%-*}
		check_version_helper $hadoop_version_number ${hadoop_min_version} ${hadoop_max_version}
        [ $? == 0 ] && (( ! force_install )) && echo " [OK]" && return 0
    else
    	echo
    	echo "No Hadoop installation detected"
    fi 

	# TODO Version detection throws deprecated HADOOP_HOME version warning 

    echo
    echo "*****************************"
    echo "Setting up Hadoop ${hadoop_version}"
    echo "*****************************"
    echo

	# Retrieve Hadoop Distribution File
	local hadoop_dist_file=${hadoop_dist_url##*/}
	local hadoop_dist_dir=$(echo ${hadoop_dist_file} | awk 'gsub(/('$compress_extensions')/,"")')

	# Check for empty distribution file (size 0)
	# TODO

	if [ ! -e ${hadoop_dist_dir} ]; then
		echo "Don't see Hadoop distribution directory ${hadoop_dist_dir}"
		wget -O "${install_prefix}/${hadoop_dist_file}" ${hadoop_dist_url}
		[ $? != 0 ] && echo " ERROR: Could not download Hadoop: ${hadoop_dist_file}" && popd && checked_done 1
		echo "Unpacking ${hadoop_dist_file}..."
		tar xzf ${install_prefix}/${hadoop_dist_file} -C ${install_prefix}
		mv "${install_prefix}/${hadoop_dist_dir}" ${hadoop_install_dir}
		[ $? != 0 ] && echo " ERROR: Could not extract Hadoop: ${hadoop_dist_file}" && popd && checked_done 1
	fi

    # Add Hadoop home to environment and TODO install manifest
	write_env_hadoop

    # Remove Hadoop Distribution File
    if [ -e "${install_prefix}/${hadoop_dist_file}" ]; then
        rm "${install_prefix}/${hadoop_dist_file}"
    fi
}

write_env_hadoop() {
	echo "export HADOOP_HOME=${hadoop_install_dir}" >> ${envfile}
	dedup ${envfile} && source ${envfile}
	return 0
}

config_hadoop() {
	# This configuration method should prompt the user to enter settings pertaining to the type
	# of Hadoop distribution (local, semi-distributed, cluster distributed). 
	# There is some info on getting Hadoop setup here: http://hadoop.apache.org/common/#Getting+Started
	echo
}

test_hadoop() {
	# This method will test hadoop in the local configuration at first, to make sure it can do a basic
	# wordcount example
	echo
}

run_hadoop() {
	# Hadoop can be run in single, locally distributed, and cluster distributed modes.
	echo
}

clean_hadoop() {
	doit="N"
    if [ -e ${hadoop_install_dir} ]; then
        read -e -p "remove mapreduce framework Hadoop? (${hadoop_install_dir}) [y/N]: " doit
        if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
        	echo "removing ${hadoop_install_dir}"
        	rm -rf ${hadoop_install_dir}
        	[ $? != 0 ] && echo "ERROR: Unable to remove ${hadoop_install_dir}"
            remove_env HADOOP_HOME
            #remove_install_log_entry hadoop
        fi  
    fi  
}

#####
# Zookeeper (Synchronization and quorum manager for clusters)
#####
setup_zookeeper() {
	echo
}

write_env_zookeeper() {
	echo
}

config_zookeeper() {
	echo
}

test_zookeeper() {
	echo
}

clean_zookeeper() {
	doit="N"
    if [ -e ${zookeeper_install_dir} ]; then
        read -e -p "remove cluster management tool Zookeeper? (${zookeeper_install_dir}) [y/N]: " doit
        if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
        	echo "removing ${zookeeper_install_dir}"
        	rm -rf ${zookeeper_install_dir}
        	[ $? != 0 ] && echo "ERROR: Unable to remove ${zookeeper_install_dir}"
            remove_env ZOOKEEPER_HOME
            #remove_install_log_entry hadoop
        fi  
    fi  
}

: << '--COMMENT--'
zookeeper_workdir=${workdir}/zookeeper
zookeeper_data_dir=${esg_root_dir}/zookeeper
zookeeper_client_port=2181

setup_zookeeper() {

    echo -n "Checking for zookeeper ${zookeeper_version}... "
    [ -x ${zookeeper_install_dir}/bin/zkServer.sh ] && check_zookeeper_version
    [ $? == 0 ] && (( ! force_install )) && echo " [OK]" && return 0

    echo
    echo "*******************************"
    echo "Setting up Zookeeper... ${zookeeper_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${zookeeper_install_dir}/bin/zkServer.sh ]; then 
        echo "Detected an existing zookeeper installation..."
        read -p "Do you want to continue with zookeeper installation and setup? [y/N] " dosetup
        if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
            echo "Skipping zookeeper installation and setup - will assume zookeeper is setup properly"
            return 0
        fi
        echo
    fi

    echo "Installing zookeeper v${zookeeper_version}"
    mkdir -p ${zookeeper_workdir}
    pushd ${zookeeper_workdir} >& /dev/null

    local zookeeper_dist_file=${zookeeper_dist_url##*/}
    local zookeeper_dist_dir=$(echo ${zookeeper_dist_file} | awk 'gsub(/('$compress_extensions')/,"")')

    #There is this pesky case of having a zero sized dist file... WTF!?
    if [ -e ${zookeeper_dist_file} ]; then
        ls -l ${zookeeper_dist_file}
        local size=$(stat -c%s ${zookeeper_dist_file})
        (( size == 0 )) && rm -v ${zookeeper_dist_file}
    fi

    #Check to see if we already have a zookeeper distribution directory
    if [ ! -e ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} ]; then
        echo "Don't see zookeeper distribution dir ${zookeeper_install_dir%/*}/${zookeeper_dist_dir}"
        if [ ! -e ${zookeeper_dist_file} ]; then
            echo "Don't see zookeeper distribution file $(pwd)/${zookeeper_dist_file} either"
            echo "Downloading zookeeper from ${zookeeper_dist_url}"
            #NOTE: this should be a checked_get call!
            #When I do the refactoring of some of the functions, then I can source that functions file and use checked_get.
            #For now just fetch it.
            wget -O ${zookeeper_dist_file} ${zookeeper_dist_url}
            [ $? != 0 ] && echo " ERROR: Could not download zookeeper ${zookeeper_dist_file}" && popd && checked_done 1
            echo "unpacking ${zookeeper_dist_file}... into ${zookeeper_install_dir%/*}"
            tar xzf ${zookeeper_dist_file} -C ${zookeeper_install_dir%/*}
            [ $? != 0 ] && echo " ERROR: Could not extract zookeeper :-( " && popd && checked_done 1
        fi
    fi
    
    #If you don't see the directory but see the tar.gz distribution
    #then expand it and go from there....
    if [ -e ${zookeeper_dist_file} ] && [ ! -e ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} ]; then
        echo "unpacking* ${zookeeper_dist_file} into ${zookeeper_install_dir%/*}"
        tar xzf ${zookeeper_dist_file} -C ${zookeeper_install_dir%/*}
        [ $? != 0 ] && echo " ERROR: Could not extract zookeeper :-( " && popd && checked_done 1
    fi

    if [ ! -e ${zookeeper_install_dir} ]; then
        ln -s ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} ${zookeeper_install_dir}
        [ $? != 0 ] && \
            echo " ERROR: Could not create sym link ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} -> ${zookeeper_install_dir}" && popd && checked_done 1
    else
        unlink ${zookeeper_install_dir}
        [ $? != 0 ] && mv ${zookeeper_install_dir} ${zookeeper_install_dir}.$(date ${date_format}).bak
        
        ln -s ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} ${zookeeper_install_dir}
        [ $? != 0 ] && \
            echo " ERROR*: Could not create sym link ${zookeeper_install_dir%/*}/${zookeeper_dist_dir} -> ${zookeeper_install_dir}" && popd && checked_done 1
    fi
    (($DEBUG)) && echo "chown -R ${installer_uid}:${installer_gid} ${zookeeper_install_dir}"
    chown    ${installer_uid}:${installer_gid} ${zookeeper_install_dir}
    chown -R ${installer_uid}:${installer_gid} $(readlink -f ${zookeeper_install_dir})
    
    popd >& /dev/null
    echo "zookeeper setup [OK]"
    return 0
}

#Helper Method to figure out the version of Zookeeper installation
check_zookeeper_version() {
    #NOTE: This would have been much sexier with sed and probably in one line... 
    #but my sed is a bit weak at the moment. :-(
    local f=$(/bin/ls ${zookeeper_install_dir} | egrep '^zookeeper.*jar$')
    f=${f%*.jar}
    f=${f#*-}
    [ "${f}" = "${zookeeper_version}" ]
}

configure_zookeeper() {
    echo -n "Configuring zookeeper... $@"
    pushd ${zookeeper_install_dir} >& /dev/null
    [ $? != 0 ] && echo " ERROR: Unable to peform configuration: no such dir ${zookeeper_install_dir}" && checked_done 1

    #old line
    #sed "s:/tmp/zookeeper:${zookeeper_data_dir}:" <(curl -s -L --insecure ${esg_dist_url}/esg-search/zookeeper/zoo.cfg) > ${zookeeper_install_dir}/conf/zoo.cfg

    #-------------
    #new hotness....
    local config_file="${zookeeper_install_dir}/conf/zoo.cfg"
    local config_info=""
    local key="${1:-dataDir}"
    local value="${2:-${zookeeper_data_dir}}"

    #Look for the local config file first.  If it is there and the key is present then do a local replacement of the value with ${zookeeper_data_dir}
    #If the file is not there OR this particular key is not present, pull the distribution config file down and to the replacement based on that content.

    if [ -f "${config_file}" ] && (grep "${key}" "${config_file}" >& /dev/null) && (( ! $force_install )); then
        config_info=$(cat "${config_file}")
    else 
        echo "fetching base config file ${config_file##*/} from distribution server..."
        config_info=$(curl -s -L --insecure ${esg_dist_url}/esg-search/zookeeper/${config_file##*/})
        (($force_install)) && cp ${config_file} ${config_file}.last
    fi
    
    (($DEBUG)) && echo "(pre) Configuration Infos:" && echo "${config_info}"

    #Now, do the value replacement based on matching against the KEY not the VALUE! (more flexible and robust)
    sed 's#\('${key}'=\)\(.*\)#\1'${value}'#g'  <(echo "${config_info}") >> ${config_file}

    #dedup the configuration file
    local tmp=$(tac ${config_file} | awk 'BEGIN {FS="="} !($1 in a) {a[$1];print $0}' | sort -k1,1)
    echo "$tmp" > ${config_file}

    
    (($DEBUG)) && echo "(post) Configuration Info:" && cat ${config_file}
    #-------------

    #Set this node's zookeeper ID
    mkdir -p ${zookeeper_data_dir}
    get_node_id > ${zookeeper_data_dir}/myid
    chown    ${installer_uid}:${installer_gid} ${zookeeper_data_dir}
    chown -R ${installer_uid}:${installer_gid} $(readlink -f ${zookeeper_data_dir})
    echo -n "zookeeper id: $(cat ${zookeeper_data_dir}/myid)"
    popd >& /dev/null
    echo " [OK]"
    return 0
}

test_zookeeper() {
    echo -n "Testing zookeeper..."
    #test client connection
    ${zookeeper_install_dir}/bin/zkCli.sh -server localhost:${zookeeper_client_port} ls / quit >& /dev/null
    ret=$?
    [ ${ret} == 0 ] && echo " [OK]" || echo " [FAIL]"
    return ${ret}
}

write_zookeeper_install_log() {
    local entry="$(date ${date_format}) esg-search:zookeeper=${zookeeper_version} ${zookeeper_install_dir}"
    echo ${entry} >> ${install_manifest}
    dedup ${install_manifest}
    return 0
}

start_zookeeper() {

    check_zookeeper_process && return 1
    echo "Starting zookeeper server on port ${zookeeper_client_port}"

    ${zookeeper_install_dir}/bin/zkServer.sh start

    #-----
    #NOTE: (potential timing issue)
    #Luca: the wait is because Solr, on startup, needs to send information to Zookeeper
    #  not sure if it is enough to wait for the client port to be accessible, we'll test
    #-----

    #Don't wait 10 seconds if you don't have to...
    #just check every second up till 10 seconds (or <= 10x)
    local wait_time=10
    local ret=1
    while [[ $wait_time > 0 ]]; do
        netstat -na | grep -i ${zookeeper_client_port}
        ret=$?
        [ $ret == 0 ] && break
        sleep 1
        ((wait_time--))
        echo -n "."
    done
    [ $ret == 0 ] && echo " [OK]" || echo " [FAIL]"
    return $ret
}

stop_zookeeper() {
    echo "Stopping zookeeper..."
    ${zookeeper_install_dir}/bin/zkServer.sh stop
    local ret=$?
    [ ${ret} == 0 ] && echo " [OK]" || echo " [FAIL]"
    return ${ret}
}

#status
check_zookeeper_process() {
    local pid=`lsof -i:${zookeeper_client_port} | grep -i java | awk '{print $2}'`
    [ -n "$pid" ] && echo " Zookeeper process running on port [${zookeeper_client_port}]... " && return 0
}

--COMMENT--

#####
# Core Methods
#####

clean_compute_tools() {
	# TODO: A few of these computation frameworks rely on one another,
	# so uninstalling portions of this suite may leave parts unstable. Some
	# sort of sanity check would be useful here.

	clean_spark
	clean_mesos
	clean_hadoop
	clean_zookeeper
}

setup_compute_tools() {
	echo
	echo "-----------------------------------"
	echo "Installing ESGF Node Compute Tools"
	echo "-----------------------------------"
	echo

	# The optimal install order, as below, depends on the following:
	# 1. Hadoop
	# 2. Zookeeper
	# 3. Mesos (Requires Zookeeper, Hadoop)
	# 4. Spark (Requires Mesos)
	# Future: Yarn (currently on Hadoop Master), Cascalog (Clojure query language for Hadoop)
	
	setup_hadoop
	setup_zookeeper
	setup_mesos
	setup_spark
}

if [[ "$BASH_SOURCE" == "$0" ]]
then
	echo
	echo "----- Setting Up Compute Tools -----"
	setup_compute_tools
fi
